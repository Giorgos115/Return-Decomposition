{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d769ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Imports\n",
    "# ===========================\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# CONFIG — edit these paths\n",
    "# ===========================\n",
    "fund_id        = \"Zimmer Utilities\"  # column name in fund_returns.csv\n",
    "benchmark_name = \"N/A\"\n",
    "description    = (\n",
    "    \"Long/Short Equity Energy & Infrastructure hedge fund focusing on \"\n",
    "    \"U.S. utilities, telecoms, oilfield services, renewables.\"\n",
    ")\n",
    "\n",
    "# Replace with your actual locations\n",
    "fund_path   = r\"C:\\Users\\...\\Qlib Data\\fund_returns.csv\"\n",
    "factor_path = r\"C:\\Users\\...\\Qlib Data\\factor_returns.csv\"\n",
    "meta_path   = r\"C:\\Users\\...\\Qlib Data\\factors_meta.json\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) LOAD & CLEAN DATA\n",
    "# ============================================================\n",
    "# The fund CSV and factor CSV are expected at monthly frequency.\n",
    "# We coerce their dates, convert % strings to decimal floats, and align them.\n",
    "\n",
    "fund_df   = pd.read_csv(fund_path)\n",
    "factor_df = pd.read_csv(factor_path)\n",
    "factors_meta: Dict[str, Dict] = json.load(open(meta_path))\n",
    "\n",
    "# --- Fund data: parse dates & convert percent strings to decimals ---\n",
    "fund_df[\"datetime\"] = pd.to_datetime(fund_df[\"datetime\"], dayfirst=True, errors=\"coerce\")\n",
    "fund_df[fund_id] = (\n",
    "    fund_df[fund_id]\n",
    "    .astype(str)                # ensure string for safe replace\n",
    "    .str.replace(\"%\", \"\", regex=False)\n",
    "    .astype(float) / 100.0      # convert % to decimal (e.g., 0.85% -> 0.0085)\n",
    ")\n",
    "\n",
    "# --- Factor data: parse dates & convert all factor columns to decimals ---\n",
    "factor_df[\"datetime\"] = pd.to_datetime(factor_df[\"datetime\"], dayfirst=True, errors=\"coerce\")\n",
    "for col in factor_df.columns.drop(\"datetime\"):\n",
    "    factor_df[col] = (\n",
    "        factor_df[col].astype(str).str.replace(\"%\", \"\", regex=False).astype(float) / 100.0\n",
    "    )\n",
    "\n",
    "# Use datetime index for clean slicing / alignment\n",
    "factor_df.set_index(\"datetime\", inplace=True)\n",
    "factor_wide = factor_df.sort_index()\n",
    "\n",
    "# The target fund series (monthly decimals)\n",
    "fund_series = (\n",
    "    fund_df\n",
    "    .set_index(\"datetime\")[fund_id]\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# --- Align both datasets on overlapping dates to avoid lookahead/holes ---\n",
    "common_dates = factor_wide.index.intersection(fund_series.index)\n",
    "if len(common_dates) == 0:\n",
    "    raise ValueError(\n",
    "        \"No overlapping dates between fund and factor files.\\n\"\n",
    "        f\"Fund date range:   {fund_series.index.min()} → {fund_series.index.max()}\\n\"\n",
    "        f\"Factor date range: {factor_wide.index.min()} → {factor_wide.index.max()}\"\n",
    "    )\n",
    "\n",
    "fund_series_aligned = fund_series.loc[common_dates]\n",
    "factor_wide         = factor_wide.loc[common_dates]\n",
    "\n",
    "# Normalize all indices to month-end for consistent monthly math/plots\n",
    "fund_series.index         = fund_series.index.to_period(\"M\").to_timestamp(\"M\")\n",
    "fund_series_aligned.index = fund_series_aligned.index.to_period(\"M\").to_timestamp(\"M\")\n",
    "factor_wide.index         = factor_wide.index.to_period(\"M\").to_timestamp(\"M\")\n",
    "\n",
    "print(\n",
    "    f\"Loaded fund data ({len(fund_series)} months) \"\n",
    "    f\"{fund_series.index.min():%Y-%m} → {fund_series.index.max():%Y-%m}\"\n",
    ")\n",
    "print(\n",
    "    f\"Loaded factor data ({len(factor_wide)} months aligned) \"\n",
    "    f\"{factor_wide.index.min():%Y-%m} → {factor_wide.index.max():%Y-%m}\"\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) ROLLING WINDOW GENERATOR\n",
    "# ============================================================\n",
    "def rolling_windows(\n",
    "    dates: pd.Index,\n",
    "    lookback_months: int,\n",
    "    test_horizon_months: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Yield (train_start, train_end, test_start, test_end) windows.\n",
    "\n",
    "    • 'dates' is monthly (we coerce to unique month-end stamps).\n",
    "    • Example with lookback=36, horizon=1:\n",
    "        [train: 36 months up to t-1], [test: month t]\n",
    "    \"\"\"\n",
    "    months = pd.to_datetime(sorted(set(pd.Period(d, \"M\").to_timestamp(\"M\") for d in dates)))\n",
    "    for i in range(lookback_months, len(months) - test_horizon_months + 1):\n",
    "        train_start = months[i - lookback_months]\n",
    "        train_end   = months[i - 1]\n",
    "        test_start  = months[i]\n",
    "        test_end    = months[i + test_horizon_months - 1]\n",
    "        yield train_start, train_end, test_start, test_end\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) ROLLING ELASTIC NET REGRESSIONS (EXPOSURES & CONTRIBUTIONS)\n",
    "# ============================================================\n",
    "# Why Elastic Net?\n",
    "# - L1+L2 regularization stabilizes exposures when factors are correlated.\n",
    "# - Cross-validation prevents overfitting and picks the best penalty balance.\n",
    "\n",
    "train_set_window = 36   # months used for model training\n",
    "test_set_window  = 1    # month ahead for out-of-sample validation\n",
    "\n",
    "roll_dates = list(\n",
    "    rolling_windows(\n",
    "        fund_series_aligned.index,\n",
    "        lookback_months=train_set_window,\n",
    "        test_horizon_months=test_set_window\n",
    "    )\n",
    ")\n",
    "\n",
    "# If there aren’t enough data points for rolling windows, fall back to full period\n",
    "if len(roll_dates) == 0:\n",
    "    print(\"⚠️  Not enough data for rolling; using full sample period instead.\")\n",
    "    roll_dates = [(\n",
    "        fund_series_aligned.index.min(),\n",
    "        fund_series_aligned.index.max(),\n",
    "        fund_series_aligned.index.min(),\n",
    "        fund_series_aligned.index.max()\n",
    "    )]\n",
    "\n",
    "# We will store exposure estimates and factor contributions for each test window\n",
    "exposure_rows: List[Dict] = []\n",
    "contrib_rows:  List[pd.Series] = []\n",
    "\n",
    "for tr_start, tr_end, te_start, te_end in roll_dates:\n",
    "    # Slice train and test windows\n",
    "    y_train = fund_series_aligned.loc[tr_start:tr_end]\n",
    "    X_train = factor_wide.loc[tr_start:tr_end]\n",
    "    y_test  = fund_series_aligned.loc[te_start:te_end]\n",
    "    X_test  = factor_wide.loc[te_start:te_end]\n",
    "\n",
    "    if len(X_train) < 12 or len(y_test) < 1:\n",
    "        continue\n",
    "\n",
    "    # Elastic Net cross-validation: small CV folds due to limited monthly data\n",
    "    cv_folds = min(5, max(2, len(X_train)//2))\n",
    "    model = ElasticNetCV(\n",
    "        cv=cv_folds, max_iter=5000,\n",
    "        l1_ratio=[0.3, 0.5, 0.8],\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    betas = dict(zip(X_train.columns, model.coef_))\n",
    "    y_true = (1 + y_test).prod() - 1  # actual compounded return over test horizon\n",
    "\n",
    "    # Save exposure summary for this test period\n",
    "    exposure_rows.append({\n",
    "        \"date\": pd.to_datetime(te_end),\n",
    "        \"intercept\": model.intercept_,\n",
    "        \"y_true\": float(y_true),\n",
    "        **{f: v for f, v in betas.items()}\n",
    "    })\n",
    "\n",
    "    # Compute the factor contributions for that period\n",
    "    contrib = (1 + X_test.mul(pd.Series(betas), axis=1)).prod() - 1\n",
    "    contrib.name = pd.to_datetime(te_end)\n",
    "    contrib_rows.append(contrib)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) GROUP FACTOR CONTRIBUTIONS (BY CATEGORY)\n",
    "# ============================================================\n",
    "# This step groups individual factor contributions into categories like:\n",
    "# \"style\", \"macro\", \"benchmark\", etc., based on factors_meta.\n",
    "\n",
    "exposure_df = pd.DataFrame(exposure_rows).set_index(\"date\").sort_index()\n",
    "contrib_df  = pd.DataFrame(contrib_rows).sort_index()\n",
    "\n",
    "def group_contributions(contrib_df: pd.DataFrame, meta: Dict[str, Dict]) -> pd.DataFrame:\n",
    "    groups: Dict[str, List[str]] = {}\n",
    "    for f in contrib_df.columns:\n",
    "        g = meta.get(f, {}).get(\"group\", \"Other\")\n",
    "        groups.setdefault(g, []).append(f)\n",
    "    return pd.DataFrame({g: contrib_df[cols].sum(axis=1) for g, cols in groups.items()})\n",
    "\n",
    "grouped = group_contributions(contrib_df, factors_meta)\n",
    "\n",
    "# Compute residual: fund return minus all explained factor groups\n",
    "aligned_fund = fund_series_aligned.reindex(grouped.index)\n",
    "grouped[\"Residual\"] = aligned_fund - grouped.sum(axis=1)\n",
    "\n",
    "# Convert to PeriodIndex for easy annualization later\n",
    "grouped.index       = grouped.index.to_period(\"M\")\n",
    "aligned_fund.index  = aligned_fund.index.to_period(\"M\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) PERFORMANCE STATISTICS (CAGR, VOL, SKEW, DRAWDOWN)\n",
    "# ============================================================\n",
    "def max_drawdown(series: pd.Series) -> float:\n",
    "    cum = (1 + series).cumprod()\n",
    "    peak = cum.cummax()\n",
    "    dd = cum / peak - 1\n",
    "    return dd.min()\n",
    "\n",
    "def stats_block(series: pd.Series) -> Dict[str, float]:\n",
    "    if len(series) < 3:\n",
    "        return {}\n",
    "\n",
    "    # Full-period statistics\n",
    "    cagr = ((1 + series).prod() ** (12 / len(series))) - 1\n",
    "    vol  = series.std() * np.sqrt(12)\n",
    "    rv   = cagr / vol if vol != 0 else np.nan\n",
    "    skew_ = skew(series)\n",
    "    kurt_ = kurtosis(series, fisher=False)\n",
    "\n",
    "    # 3-year rolling stats (if enough data)\n",
    "    if len(series) >= 36:\n",
    "        last36 = series[-36:]\n",
    "        cagr_3y = ((1 + last36).prod() ** (12 / 36)) - 1\n",
    "        vol_3y  = last36.std() * np.sqrt(12)\n",
    "        rv_3y   = cagr_3y / vol_3y if vol_3y != 0 else np.nan\n",
    "    else:\n",
    "        cagr_3y, vol_3y, rv_3y = cagr, vol, rv\n",
    "\n",
    "    worst_month = series.min()\n",
    "    worst_dd    = max_drawdown(series)\n",
    "\n",
    "    return {\n",
    "        \"Full Ann. Return (%)\": cagr * 100,\n",
    "        \"Full Ann. Vol (%)\": vol * 100,\n",
    "        \"Full Ret/Vol\": rv,\n",
    "        \"Skewness\": skew_,\n",
    "        \"Kurtosis\": kurt_,\n",
    "        \"3Y Ann. Return (%)\": cagr_3y * 100,\n",
    "        \"3Y Ann. Vol (%)\": vol_3y * 100,\n",
    "        \"3Y Ret/Vol\": rv_3y,\n",
    "        \"Worst Month (%)\": worst_month * 100,\n",
    "        \"Max Drawdown (%)\": worst_dd * 100\n",
    "    }\n",
    "\n",
    "# Evaluate across different components\n",
    "manager  = fund_series.dropna()\n",
    "factors  = grouped.get(\"style\", pd.Series(0, index=grouped.index))\n",
    "bench    = grouped.get(\"benchmark\", pd.Series(0, index=grouped.index))\n",
    "resid    = grouped[\"Residual\"]\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Manager\":  stats_block(manager),\n",
    "    \"Factors\":  stats_block(factors),\n",
    "    \"Benchmark\": stats_block(bench),\n",
    "    \"Residual\": stats_block(resid),\n",
    "})\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) R² CALCULATION — HOW WELL DO FACTORS EXPLAIN RETURNS?\n",
    "# ============================================================\n",
    "def r2_score_academic(y: pd.Series, yhat: pd.Series) -> float:\n",
    "    y = y.dropna()\n",
    "    yhat = yhat.reindex(y.index).fillna(0)\n",
    "    if len(y) < 3 or y.var() == 0:\n",
    "        return np.nan\n",
    "    ssr = ((y - yhat)**2).sum()\n",
    "    sst = ((y - y.mean())**2).sum()\n",
    "    return 1 - ssr / sst\n",
    "\n",
    "explained = grouped.drop(columns=\"Residual\", errors=\"ignore\").sum(axis=1)\n",
    "aligned_mgr = manager.reindex(explained.index).fillna(0)\n",
    "\n",
    "r2_full   = r2_score_academic(aligned_mgr, explained)\n",
    "half      = len(aligned_mgr)//2\n",
    "r2_first  = r2_score_academic(aligned_mgr.iloc[:half], explained.iloc[:half])\n",
    "r2_second = r2_score_academic(aligned_mgr.iloc[half:], explained.iloc[half:])\n",
    "\n",
    "print(f\"Full-sample R²: {r2_full:.3f} | First half: {r2_first:.3f} | Second half: {r2_second:.3f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) VISUALIZATION — ATTRIBUTION AND EXPOSURES\n",
    "# ============================================================\n",
    "\n",
    "# Convert PeriodIndex → DatetimeIndex for plotting\n",
    "plot_index = grouped.index.to_timestamp(\"M\")\n",
    "\n",
    "# --- (1) Cumulative Return Decomposition ---\n",
    "cum = (1 + grouped).cumprod() - 1\n",
    "cum.index = plot_index\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for col in grouped.columns:\n",
    "    if col != \"Residual\":\n",
    "        plt.plot(cum.index, cum[col]*100, label=col, linewidth=2)\n",
    "if \"Residual\" in cum.columns:\n",
    "    plt.plot(cum.index, cum[\"Residual\"]*100, label=\"Residual\", linestyle=\"--\", color=\"black\")\n",
    "plt.title(f\"Cumulative Return Decomposition — {fund_id}\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend(); plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- (2) Average Factor Contribution Bar Chart ---\n",
    "if not contrib_df.empty:\n",
    "    avg_contrib = contrib_df.mean().sort_values(ascending=False)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    avg_contrib.plot(kind=\"bar\", color=\"steelblue\")\n",
    "    plt.axhline(0, color=\"black\")\n",
    "    plt.title(f\"Average Monthly Contribution by Factor — {fund_id}\")\n",
    "    plt.ylabel(\"Monthly Contribution (decimal)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- (3) Explained vs Residual Stacked Bar ---\n",
    "expl = grouped.drop(columns=\"Residual\", errors=\"ignore\").sum(axis=1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(plot_index, expl*100, label=\"Explained\", color=\"steelblue\")\n",
    "plt.bar(plot_index, grouped[\"Residual\"]*100,\n",
    "        bottom=expl*100, label=\"Residual\", color=\"orange\")\n",
    "plt.title(f\"Explained vs Residual Monthly Returns — {fund_id}\")\n",
    "plt.ylabel(\"Monthly Return (%)\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- (4) Rolling R² (36-month window) ---\n",
    "rolling_r2 = aligned_mgr.rolling(36).apply(\n",
    "    lambda x: r2_score_academic(x, explained.loc[x.index]), raw=False\n",
    ")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rolling_r2.index, rolling_r2*100, color=\"darkgreen\", label=\"Rolling 3Y R²\")\n",
    "plt.axhline(r2_full*100, linestyle=\"--\", color=\"red\", label=\"Full-sample R²\")\n",
    "plt.title(f\"Rolling 3-Year R² — {fund_id}\")\n",
    "plt.ylabel(\"R² (%)\"); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- (5) Factor Exposure Heatmap ---\n",
    "if not exposure_df.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(\n",
    "        exposure_df.drop(columns=[\"intercept\", \"y_true\"], errors=\"ignore\").T,\n",
    "        cmap=\"RdBu_r\", center=0, cbar_kws={\"label\": \"Beta\"}\n",
    "    )\n",
    "    plt.title(f\"Rolling Factor Exposures — {fund_id}\")\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(\"Factor\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- (6) Average Group Contribution Bar Chart ---\n",
    "avg_group = grouped.drop(columns=\"Residual\", errors=\"ignore\").mean()\n",
    "plt.figure(figsize=(8, 5))\n",
    "avg_group.sort_values().plot(kind=\"barh\", color=\"steelblue\")\n",
    "plt.axvline(0, color=\"black\")\n",
    "plt.title(f\"Average Contribution by Group — {fund_id}\")\n",
    "plt.xlabel(\"Average Monthly Contribution\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) PRINT SUMMARY TABLES\n",
    "# ============================================================\n",
    "print(\"\\n===== PERFORMANCE STATISTICS =====\")\n",
    "print(stats_df.round(2).to_string())\n",
    "\n",
    "print(\"\\n===== R-SQUARED SUMMARY =====\")\n",
    "print(f\"Full: {r2_full:.3f},  1st Half: {r2_first:.3f},  2nd Half: {r2_second:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
